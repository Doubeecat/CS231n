# L5:卷积神经网络

卷积神经网络和神经网络的想法基本一样，但是我们训练的是卷积层，更可以保证特征的保留。整个网络仍表示为一个可微分的评分函数：从一端输入原始图像像素，到另一端输出类别得分。最后一层（全连接层）仍使用SVM/Softmax等损失函数，此前为常规神经网络开发的所有训练技巧仍适用。

## 原理

此前的全连接层类似于把 32x32x3 的图像信息拍扁成 3072x1 的矩阵，然后再通过中间的 $W_x$ 层去得到最后的 10 个输出。而卷积层的特点在于，保留了 32x32x3 的整体结构，然后通过一些比较小(比如 5x5x3) 的卷积核 $w$，通过在整个空间里滑动算出具体细节，也就是从 $T$ 中选取一个 5x5 的子层数，然后用：$T\times w^{T} + b$ 得到每个位置的值，具体计算时候我们可能还是运用类似转置的东西来进行，即虽然看着是一个卷积核，但是实际上我们还是用向量的计算来进行。

根据本质不同的卷积核个数，我们可以得到若干层卷积层。前面的卷积层我们学习到的可能是一些低阶特征，比如说边缘特征。中间层我们可以得到更加复杂的特征，比如边角和斑点……

接下来引入一个东西叫池化层，